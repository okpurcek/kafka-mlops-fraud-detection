# üõ°Ô∏è Real-Time Fraud Detection with Apache Kafka & MLOps

This repository contains a demonstration of a **Real-Time Anomaly Detection System** built for banking transactions. It serves as a practical implementation of **MLOps principles** using **Apache Kafka** as the central nervous system.

---

## üß† Why Apache Kafka? (The Core Concept)

In traditional ML systems, data is often processed in batches (e.g., once a day). However, fraud detection requires **immediate action**.

**Apache Kafka** solves this by enabling an **Event-Driven Architecture**:

1.  **Decoupling:** The application generating transactions (`Producer`) does not know about the fraud detector (`Consumer`). They operate independently.
2.  **High Throughput:** Kafka can handle millions of events per second with very low latency.
3.  **Durability:** Data is stored safely in "Topics" (logs), allowing multiple consumers to read the same data for different purposes (e.g., one for fraud detection, another for data warehousing).

### How It Works in This Demo

We simulate a banking environment where credit card transactions flow continuously:

```mermaid
graph LR
    A["Transaction Generator<br>(Producer.py)"] -- Pushes JSON Events --> B(("Kafka Broker<br>Topic: 'transactions'"))
    B -- Streams Events --> C["Fraud Detector Dashboard<br>(Consumer / Streamlit)"]
    style B fill:#f9f,stroke:#333,stroke-width:4px
````

  * **Topic:** `transactions` (The channel where data flows)
  * **Producer:** Simulates credit card usage (Injects random anomalies).
  * **Consumer:** Reads the stream, applies a rule-based logic to detect fraud, and visualizes it.

-----

## üèóÔ∏è Project Architecture

| Component | Technology | Description |
| :--- | :--- | :--- |
| **Infrastructure** | Docker & Docker Compose | Runs a single-node Kafka Broker and Zookeeper. |
| **Data Producer** | Python (`kafka-python`) | Generates synthetic transaction data (Amount, City, Time). |
| **Message Broker** | **Apache Kafka** | Buffers and streams data asynchronously. |
| **Model Serving** | Streamlit & Pandas | Consumes data in real-time and visualizes anomalies. |

-----

## üöÄ Quick Start Guide

Follow these steps to run the system on your local machine.

### Prerequisites

  * **Docker Desktop** (Must be running)
  * **Python 3.8+**

### 1\. Start the Kafka Infrastructure

We use Docker to spin up the Kafka environment without complex installation.

```bash
docker-compose up -d
```

*Wait \~30 seconds for the containers to fully initialize.*

### 2\. Install Dependencies

Create a virtual environment (optional) and install the required libraries.

```bash
pip install -r requirements.txt
```

### 3\. Run the Demo (Two Terminals Required)

To see the "Streaming" effect, you need to run the producer and consumer simultaneously.

**Terminal 1: The Transaction Generator**
This script acts as the "World," generating continuous financial events.

```bash
python producer.py
```

*You will see logs like:* `[‚úÖ OK] Sent: $120` or `[üö® FRAUD] Sent: $15000`

**Terminal 2: The Dashboard**
This launches the real-time monitoring interface.

```bash
streamlit run dashboard.py
```

*The dashboard will automatically open in your browser at http://localhost:8501*

-----

## üìä Scenarios to Watch

Once the dashboard is running, watch for the following events generated by the producer:

1.  **Normal Traffic:** Small amounts (e.g., $50, $120) from known cities (Istanbul, London, Tokyo).
2.  **The Anomaly (Fraud):**
      * **High Amount:** Suddenly a transaction \> $5,000 appears.
      * **Suspicious Location:** The location is flagged as `UNKNOWN_IP_ADDR`.
      * **Result:** The dashboard graph spikes, and a **RED ALERT** box appears instantly.

-----

## üìÇ Repository Structure

  * `docker-compose.yml`: Configuration for Kafka and Zookeeper containers.
  * `producer.py`: Python script to simulate real-time data stream.
  * `dashboard.py`: Streamlit application for visualization and detection logic.
  * `requirements.txt`: List of Python libraries used.

-----

## üìö Educational Resources

  * [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
  * [Streamlit Documentation](https://docs.streamlit.io/)

## üìú License

This project is open-source and available under the MIT License.
